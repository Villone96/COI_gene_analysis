{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiime2\n",
    "from tempfile import mkdtemp\n",
    "from qiime2.plugins import demux, deblur, quality_filter, \\\n",
    "                           metadata, feature_table, alignment, \\\n",
    "                           phylogeny, diversity, emperor, feature_classifier, \\\n",
    "                           taxa, composition\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from Bio import Entrez\n",
    "from pprint import pprint\n",
    "from sklearn.utils import shuffle\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Studies\n",
    "* exercise_frequency\n",
    "* flossing_frequency\n",
    "* vitamin_d_supplement_frequency\n",
    "* weight_change\n",
    "* fruit_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_workspace():\n",
    "    starting_path = os.getcwd()\n",
    "    path = os.path.join(os.getcwd(), f'result_extraction')\n",
    "    os.chdir(path)\n",
    "    \n",
    "    files = os.listdir()\n",
    "    for file in files:\n",
    "        if file != 'sra_querying.log':\n",
    "            delete_command = f'rm -r {file}'\n",
    "            os.system(delete_command)\n",
    "            \n",
    "    delete_old_log = 'cat > sra_querying.log'\n",
    "    os.system(delete_old_log)     \n",
    "    os.chdir(starting_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCBI utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = \"giacomo.villa.mi@gmail.com\"\n",
    "\n",
    "def good_print(text):\n",
    "    print(pprint(text))\n",
    "\n",
    "def esearch(db, query, num_max = 20):\n",
    "    handle = Entrez.esearch(db = db, term = query, retmax = num_max)\n",
    "    record = Entrez.read(handle, validate = True)\n",
    "    return record\n",
    "\n",
    "def esummary(db, id_val):\n",
    "    handle = Entrez.esummary(db = db, id = id_val)\n",
    "    record = Entrez.read(handle, validate = True)\n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Sample generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_age_mean(total, man, woman, typology, experiment):\n",
    "    \n",
    "    mean_age_total = round(np.mean(total['age_years']), 4)\n",
    "    mean_age_man = round(np.mean(man['age_years']), 4)\n",
    "    mean_age_woman = round(np.mean(woman['age_years']), 4)\n",
    "    not_valid_sex = total.query(\"sex != 'female' and sex != 'male'\")\n",
    "    \n",
    "    if typology != 'sample':\n",
    "        logging.info(f'--------------------{typology.upper()}--------------------')\n",
    "    logging.info(f'Total number of {typology} people: {len(total)}')\n",
    "    logging.info(f'Total number of {typology} man: {len(man)}')\n",
    "    logging.info(f'Total number of {typology} woman: {len(woman)}')\n",
    "    logging.info(f'Total number of non valid sex {len(not_valid_sex)}')\n",
    "    \n",
    "    logging.info(f'Mean Age for total: {mean_age_total}')\n",
    "    logging.info(f'Mean Age for man: {mean_age_man}')\n",
    "    logging.info(f'Mean Age for woman: {mean_age_woman}')\n",
    "    logging.info(f'\\n')\n",
    "    \n",
    "    print(f'--------------------{typology.upper()}--------------------')\n",
    "    print(f'Total number of {typology} people: {len(total)}')\n",
    "    print(f'Total number of {typology} man: {len(man)}')\n",
    "    print(f'Total number of {typology} woman: {len(woman)}')\n",
    "    print(f'Total number of non valid sex {len(not_valid_sex)}')\n",
    "    \n",
    "    print(f'Mean Age for total: {mean_age_total}')\n",
    "    print(f'Mean Age for man: {mean_age_man}')\n",
    "    print(f'Mean Age for woman: {mean_age_woman}')\n",
    "    \n",
    "    starting_path = os.getcwd()\n",
    "    path = os.path.join(os.getcwd(), f'result_extraction/')\n",
    "    os.chdir(path)\n",
    "    directories = os.listdir()\n",
    "    if f'{experiment}' not in directories:\n",
    "        os.mkdir(f'{experiment}')\n",
    "        \n",
    "    os.chdir(f'{experiment}')\n",
    "    if typology != 'sample':\n",
    "        total.to_csv(f\"./dataset_query_result_{typology}.csv\", index=False, encoding='utf-8')\n",
    "    \n",
    "    os.chdir(starting_path)\n",
    "\n",
    "# Prende in input il dataset da cui campionare e gli index degli element già presi, finché non campiona qualcosa di \n",
    "# nuovo non termina\n",
    "def generate_single_sample(already_taken, from_df):\n",
    "    element = random.randint(0, len(from_df) - 1)\n",
    "    while (element in already_taken or from_df.iloc[element]['sample_name'] == '10317' or \n",
    "           len(str(from_df.iloc[element]['sample_name'])) > 15):\n",
    "        element = random.randint(0, len(from_df) - 1)\n",
    "    return element\n",
    "\n",
    "# Dato il dataset di partenza contenente solo elementi effettivamente presenti su NCBI\n",
    "# genera un nuovo dataset composto da n_samples elementi\n",
    "def get_final_sample(started_dataset, n_samples):\n",
    "    taken = set()\n",
    "    final_sample = pd.DataFrame(columns=started_dataset.columns)\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        new_sample = generate_single_sample(taken, started_dataset)\n",
    "        taken.add(new_sample)\n",
    "        final_sample = final_sample.append(started_dataset.iloc[new_sample], ignore_index=True)\n",
    "    return final_sample\n",
    "\n",
    "    \n",
    "# Dato il dataset di partenza con tutti gli elementi che rispettano la query posta al gut, tiene in considraz\n",
    "def sampling_data(typology, n_samples, experiment):\n",
    "    valid_id = list()\n",
    "    print(os.getcwd())\n",
    "    start_dataset = pd.read_csv(f'./result_extraction/{experiment}/dataset_query_result_{typology}.csv')\n",
    "    for try_id in tqdm(start_dataset['sample_name']):\n",
    "        handleSce = esearch('biosample', try_id)\n",
    "        if try_id != '10317':\n",
    "            if len(handleSce['IdList']) != 0:\n",
    "                #print(handleSce['IdList'])\n",
    "                #print(try_id)\n",
    "                #print()\n",
    "                valid_id.append(try_id)\n",
    "            \n",
    "    print(f'Total rows: {len(start_dataset)}')\n",
    "    print(f'Valid rows: {len(valid_id)}')\n",
    "    \n",
    "    logging.info(f'Total rows: {len(start_dataset)}')\n",
    "    logging.info(f'Valid rows: {len(valid_id)}')\n",
    "            \n",
    "    valid_start_dataset = pd.DataFrame(columns=start_dataset.columns)\n",
    "    index = 0\n",
    "    for _, row in tqdm(start_dataset.iterrows()):\n",
    "        if row['sample_name'] in valid_id:\n",
    "            valid_start_dataset.loc[index] = row\n",
    "            index += 1\n",
    "            \n",
    "    valid_start_dataset = shuffle(valid_start_dataset)\n",
    "    final_sample = get_final_sample(valid_start_dataset, n_samples)\n",
    "    write_sample_info(final_sample, typology, experiment)\n",
    "\n",
    "# Funzione richiamata sul sample finale, traduce in csv il campione finale creando un csv di due colonne: sample_name,\n",
    "# typology (e.g. healthy/not_healthy), richiama write_age_mean per scrivere sul log file l'età media dei soggetti\n",
    "def write_sample_info(sample, typology, experiment):\n",
    "    man = sample.query(\"sex == 'male'\")\n",
    "    woman = sample.query(\"sex == 'female'\")\n",
    "    write_age_mean(sample, man, woman, 'sample', experiment)\n",
    "    \n",
    "    for _, row in tqdm(sample.iterrows()):\n",
    "        if len(str(row['sample_name'])) != 15:\n",
    "            print(row['sample_name'])\n",
    "    \n",
    "    sample = sample[['sample_name']]\n",
    "    sample['typology'] = [typology]*len(sample)\n",
    "    \n",
    "    files = os.listdir(f'./result_extraction/{experiment}')\n",
    "    \n",
    "    if f'final_sample_{experiment}.csv' in files:\n",
    "        final_sample = pd.read_csv(f\"./result_extraction/{experiment}/final_sample_{experiment}.csv\", header=0)\n",
    "        final_sample = final_sample[['sample_name', 'typology']]\n",
    "        elements = [final_sample, sample]\n",
    "        final_sample = pd.concat(elements, ignore_index=False, sort=False)\n",
    "        final_sample.to_csv(f\"./result_extraction/{experiment}/final_sample_{experiment}.csv\", index=False)\n",
    "    else:\n",
    "        sample.to_csv(f\"./result_extraction/{experiment}/final_sample_{experiment}.csv\", index=False)\n",
    "        \n",
    "    close_dashes = '-'*len(typology.upper())\n",
    "    logging.info(f'--------------------{close_dashes}--------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRA operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione controller, prende in input il nome dell'esperimento (eg. healthy vs not_healthy) e le tipologie di campione\n",
    "# (e.g. healthy e not_healty), chiama la funzione che interroga SRA di NCBI, in seguito richiama la funzione per \n",
    "# concatenare i file fasta e infine la funzione per prendere le sequenze che ricorrono più spesso. Infine salva su un\n",
    "# file csv i fasta delle sequenze più popolose aggiungendo il campo che si rifà all'id di Biosample.\n",
    "# Il file csv delle frequenze più popole è l'input per blast\n",
    "def sra_querying(experiment, types):\n",
    "    \n",
    "    # Legge il csv contente i 30 campioni di una tipologia e i 30 campioni dell'altra tipologia dato l'esperimento\n",
    "    # (e.g. esperimento: healthy vs not_healthy estrare il csv che contiene i 30 sample_name degli healthy e i \n",
    "    # 30 sample_name dei not_healthy)\n",
    "    final_sample = pd.read_csv(f\"./result_extraction/{experiment}/final_sample_{experiment}.csv\", header=0)\n",
    "    \n",
    "    # crea una lista che conterrà, dati i record, il corrispettivo id di Biosample\n",
    "    bio_sample_id = list()\n",
    "    \n",
    "    # per ogni riga del csv dei 30 campioni di una tipologia e i 30 dell'altra tipologia dato l'esperimento\n",
    "    for index, row in final_sample.iterrows():\n",
    "        print(f'File number: {index+1}')\n",
    "        \n",
    "        # Gestione del problema sulla lettura di un sample_name con la concatenazione della stringa '001'\n",
    "        # in generale estrae l'input per la funzione che farà la query su SRA\n",
    "        record_id = str(row[0])[0:15]\n",
    "        print(str(row[0]))\n",
    "        print(record_id)\n",
    "        record_typology = row[1]\n",
    "        \n",
    "        # data la singola interrogazione, aggiunge alla lista degli id di bio_sample l'id.\n",
    "        bio_sample_id.append(get_sequences(record_id, record_typology, experiment))\n",
    "        \n",
    "    # una volta scaricate tutti i file fasta data l'esperimento, per ogni tipologia (e.g healthy/not_healthy) \n",
    "    # crea un unico file con tutte le sequenze e poi prende, da questo file, solo quelle più popolose\n",
    "    for typology in types:\n",
    "        concatenate_fast_file(typology, 'fasta', experiment)\n",
    "        get_top_sequences(typology, experiment)\n",
    "        \n",
    "    # crea una nuova colonna dove, per ogni sample_name, vi sarà l'id di biosample associato e salva il nuovo csv\n",
    "    final_sample['bio_sample_id'] = bio_sample_id\n",
    "    final_sample.to_csv(f\"./result_extraction/{experiment}/final_sample_{experiment}.csv\", index=False)\n",
    "    \n",
    "# Funzione che interroga SRA, dato il sample_name. Richiede anche la tipologia del campione (e.g. healthy o not_healthy)\n",
    "# e il nome dell'esperimento (e.g. healthy_vs_not_healthy), per andare a salvare correttamente nelle cartelle facenti\n",
    "# riferimento all'esperimento\n",
    "def get_sequences(sample_name, typology, experiment):\n",
    "    \n",
    "    # in funzione della tipologia del campione (e.g. healthy o not_healthy) e dell'esperimento (e.g. healthy_vs_not_healthy)\n",
    "    # definisce il path corretto dove andare a salvare il risultato\n",
    "    path = f'\"./result_extraction/{experiment}/SRA_{typology}\" '\n",
    "    command1 = f'fastq-dump --fasta --readids --outdir {path}'\n",
    "    command2 = f'fastq-dump --readids --outdir {path}'\n",
    "        \n",
    "    # Query su SRA e print utili\n",
    "    print(f'Sample id: {sample_name}')\n",
    "    handleSce = esearch('biosample', sample_name)\n",
    "    biosampleId = handleSce['IdList'][0]\n",
    "    print(f'Biosample ID {biosampleId}')\n",
    "    print(f'Typology: {typology}')\n",
    "    handleSra = Entrez.efetch(db='biosample', id=biosampleId, retmode='xml')\n",
    "    root = ET.fromstring(handleSra.read())\n",
    "    identifier = root.findall('.//BioSample//Ids//Id')\n",
    "    for i in identifier:\n",
    "        if i.attrib['db'] == 'SRA':\n",
    "            sraId = i.text\n",
    "    print(f'SRA ID: {sraId}')\n",
    "    handleSra = Entrez.esearch(db='sra', term=sraId)\n",
    "    resultsSra = Entrez.read(handleSra)['IdList']\n",
    "    print(resultsSra)\n",
    "    for s in resultsSra:\n",
    "        handlesngSraId = Entrez.efetch(db='sra', id=s, retmode='xml')\n",
    "        root = ET.fromstring(handlesngSraId.read())\n",
    "        identifier = root.find('.//EXPERIMENT_PACKAGE//RUN_SET//RUN')\n",
    "        runId = identifier.attrib['accession']\n",
    "        #os.system(command1 + runId)\n",
    "        #os.system(command2 + runId) \n",
    "    print()\n",
    "    return biosampleId\n",
    "        \n",
    "\n",
    "# Dato il risultato delle query su SRA, concatena i file fasta facenti riferimento a una certa tipologia di record\n",
    "# (e.g. healthy o not_healthy) dato un certo esperimento (e.g. healthy_vs_not_healthy)\n",
    "def concatenate_fast_file(typology, file_format, experiment):\n",
    "    \n",
    "    # Prende tutti i file data la tipologia del record (e.g. healthy o not_healthy) contenuti nella cartella dove,\n",
    "    # dato l'esperimento (e.g. healthy_vs_not_healthy), la query su SRA ha riposto i risultati\n",
    "    files = os.listdir(f'./result_extraction/{experiment}/SRA_{typology}')\n",
    "    \n",
    "    # concatenazione file fasta\n",
    "    compact_files = list()\n",
    "    for file in files:\n",
    "        if file_format in file:\n",
    "            f = open(f'./result_extraction/{experiment}/SRA_{typology}/{file}', \"r\")\n",
    "            compact_files.append(f.read())\n",
    "            f.close()\n",
    "    f = open(f'./result_extraction/{experiment}/SRA_{typology}/final_{file_format}_{typology}.{file_format}', 'w')\n",
    "    for file in compact_files:\n",
    "        f.write(file)\n",
    "    f.close()\n",
    "    \n",
    "    # Eliminazione dei \n",
    "    starting_path = os.getcwd()\n",
    "    path = os.path.join(os.getcwd(), f'result_extraction/{experiment}/SRA_{typology}')\n",
    "    os.chdir(path)\n",
    "    command = 'rm *[0-9].fasta'\n",
    "    os.system(command) \n",
    "    os.chdir(starting_path)\n",
    "        \n",
    "def get_top_sequences(typology, experiment):\n",
    "    records = list(SeqIO.parse(f\"./result_extraction/{experiment}/SRA_{typology}/final_fasta_{typology}.fasta\", format=\"fasta\"))\n",
    "    print(f'Number of sequences for {typology}: {len(records)}')\n",
    "    logging.info(f'Number of sequences for {typology}: {len(records)}')\n",
    "    \n",
    "    sequences = dict()\n",
    "    for record in tqdm(records):\n",
    "        if record.seq in sequences:\n",
    "            sequences[record.seq][0] += 1\n",
    "        else:\n",
    "            sequences[record.seq] = [1, f'>{record.description}']\n",
    "    \n",
    "    print(f'Number of grouped sequences: {len(sequences)}')\n",
    "    logging.info(f'Number of grouped sequences: {len(sequences)}')\n",
    "    \n",
    "    cont = 0\n",
    "    f = open(f'./result_extraction/{experiment}/SRA_{typology}/top_sequences_{typology}.fasta', 'w')\n",
    "    \n",
    "    for element in sequences:\n",
    "        if sequences[element][0] >= 100:\n",
    "            f.write(f'{sequences[element][1]} number of reps {sequences[element][0]}')\n",
    "            f.write('\\n')\n",
    "            f.write(str(element))\n",
    "            f.write('\\n')\n",
    "            cont += 1\n",
    "    f.close()\n",
    "    \n",
    "    print(f'Number of taken sequences: {cont}')\n",
    "    logging.info(f'Number of taken sequences: {cont}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il dataset gut\n",
    "df = pd.read_csv(\"./data/american_gut.txt\", delimiter=\"\\t\", header=0)\n",
    "\n",
    "# Sostituisce con NAN valori non validi\n",
    "df.replace(' ', np.nan, inplace=True)\n",
    "df.replace('Not provided', np.nan, inplace=True)\n",
    "df.replace('Unspecified', np.nan, inplace=True)\n",
    "\n",
    "# Elimina dalla working directory tutti i risultati dello scorso esperimento, ripulisce il logfile\n",
    "clean_workspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizializza il log file\n",
    "logging.basicConfig(filename='./result_extraction/sra_querying.log', level=logging.INFO, format='%(message)s')\n",
    "today = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "logging.info(f'RUN TIME: {today}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    print(column, end = ', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Healthy vs not healthy study\n",
    "### Healthy extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estraiamo dal dataset i dati di interesse\n",
    "healthy = df.query(\"smoking_frequency == 'Never' and alcohol_frequency == 'Never'\")\n",
    "\n",
    "healthy = healthy.query(\"cancer == 'I do not have this condition'\")\n",
    "\n",
    "healthy['bmi'] = healthy['bmi'].apply(lambda x: float(x))\n",
    "healthy = healthy.query(\"bmi >= 18.5 and bmi <= 24.99\")\n",
    "\n",
    "healthy['age_years'] = healthy['age_years'].apply(lambda x: float(x))\n",
    "healthy = healthy.query(\"age_years >= 20 and age_years <= 50\")\n",
    "\n",
    "healthy = healthy.query(\"body_site == 'UBERON:feces'\")\n",
    "\n",
    "healthy_man = healthy.query(\"sex == 'male'\")\n",
    "healthy_woman = healthy.query(\"sex == 'female'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrive a console e su log file età media dei campioni, crea file csv con copia dei record estratti date tutte le \n",
    "# colonne del dataset gut\n",
    "write_age_mean(healthy, healthy_man, healthy_woman, 'healthy', 'healthy_vs_not_healthy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Controlla che agli ids sia associato un record su biosample, su quelli effettivamente validi campiona casualmente\n",
    "# 30 elementi senza ripetizioni. Scrive file csv con i campioni estratti, il file avrà due colonne: sample_name categoria\n",
    "sampling_data('healthy', 30, 'healthy_vs_not_healthy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not healthy extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_healthy = df.query(\"smoking_frequency == 'Occasionally (1-2 times/week)' or smoking_frequency == 'Daily' or smoking_frequency == 'Regularly (3-5 times/week)'\")\n",
    "not_healthy = not_healthy.query(\"alcohol_frequency == 'Occasionally (1-2 times/week)' or alcohol_frequency == 'Daily' or alcohol_frequency == 'Regularly (3-5 times/week)'\")\n",
    "\n",
    "not_healthy = not_healthy.query(\"cancer == 'I do not have this condition'\")\n",
    "\n",
    "not_healthy['bmi'] = not_healthy['bmi'].apply(lambda x: float(x))\n",
    "not_healthy = not_healthy.query(\"bmi < 18.5 or bmi > 24.99\")\n",
    "\n",
    "not_healthy['age_years'] = not_healthy['age_years'].apply(lambda x: float(x))\n",
    "not_healthy = not_healthy.query(\"age_years >= 20 and age_years <= 50\")\n",
    "\n",
    "not_healty = not_healthy.query(\"body_site == 'UBERON:feces'\")\n",
    "\n",
    "not_healthy_man = not_healthy.query(\"sex == 'male'\")\n",
    "not_healthy_woman = not_healthy.query(\"sex == 'female'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_age_mean(not_healthy, not_healthy_man, not_healthy_woman, 'not_healthy', 'healthy_vs_not_healthy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_data('not_healthy', 30, 'healthy_vs_not_healthy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mental illness vs food disorders\n",
    "### Mental illness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mental_illness = df.query(\"country_residence == 'United States'\")\n",
    "\n",
    "mental_illness = mental_illness.query(\"body_site == 'UBERON:feces'\")\n",
    "\n",
    "mental_illness = mental_illness.query(\"mental_illness == 'true' or mental_illness == 'Yes'\")\n",
    "\n",
    "mental_illness['age_years'] = mental_illness['age_years'].apply(lambda x: float(x))\n",
    "\n",
    "mental_illness_man = mental_illness.query(\"sex == 'male'\")\n",
    "mental_illness_woman = mental_illness.query(\"sex == 'female'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_age_mean(mental_illness, mental_illness_man, mental_illness_woman, 'mental_illness', 'mental_ill_vs_food_dis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_data(mental_illness, 'mental_illness', 30, 'mental_ill_vs_food_dis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food disorders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_disorders = df.query(\"country_residence == 'United States'\")\n",
    "\n",
    "food_disorders = food_disorders.query(\"body_site == 'UBERON:feces'\")\n",
    "\n",
    "food_disorders = food_disorders.query(\"mental_illness == 'false' or mental_illness == 'No'\")\n",
    "\n",
    "food_disorders['bmi'] =  food_disorders['bmi'].apply(lambda x : float(x))\n",
    "food_disorders = food_disorders.query(\"bmi < 18.5 or bmi > 24.99\")\n",
    "\n",
    "food_disorders = food_disorders.query(\"(fruit_frequency == 'Never' or fruit_frequency == 'Rarely (less than once/week)')\")\n",
    "\n",
    "food_disorders = food_disorders.query(\"exercise_frequency=='Rarely (a few times/month)' or exercise_frequency=='Never'\")\n",
    "\n",
    "food_disorders['age_years'] = food_disorders['age_years'].apply(lambda x: float(x))\n",
    "\n",
    "food_disorders_man = food_disorders.query(\"sex == 'male'\")\n",
    "food_disorders_woman = food_disorders.query(\"sex == 'female'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_age_mean(food_disorders, food_disorders_man, food_disorders_woman, 'food_disorders', 'mental_ill_vs_food_dis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_data('food_disorders', 30, 'mental_ill_vs_food_dis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NCBI Quering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sra_querying('mental_ill_vs_food_dis', ['mental_illness', 'food_disorders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sra_querying('healthy_vs_not_healthy', ['healthy', 'not_healthy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project_bio",
   "language": "python",
   "name": "final_project_bio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
