{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nmtVO5c7Xso2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import os\n",
    "import glob\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import time\n",
    "from Bio.Blast.Applications import NcbiblastnCommandline\n",
    "from urllib.error import HTTPError\n",
    "from ete3 import NCBITaxa\n",
    "ncbi = NCBITaxa()\n",
    "\n",
    "#variables necessary for the script functions:\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4tCseJ7bTKY"
   },
   "outputs": [],
   "source": [
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1,\n",
    "                        length = 100, fill = 'â–ˆ', printEnd = \"\\r\"):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total:\n",
    "        print()\n",
    "\n",
    "\n",
    "def seq_blast(pathwd, inputfile, split_len, split_dir):\n",
    "    os.chdir(pathwd)\n",
    "    #names of the output file(removing dot):\n",
    "    outputname=inputfile.split(\".\")[0]\n",
    "    wd=os.getcwd()\n",
    "    print(wd)\n",
    "    #make working directory:\n",
    "    while(True):\n",
    "        splitdir=str(split_dir)\n",
    "        try:\n",
    "            os.makedirs(\"./\"+splitdir)\n",
    "            break\n",
    "        except FileExistsError as err:\n",
    "            break\n",
    "\n",
    "    #read and split file in lines:\n",
    "    splitLen=int(split_len)\n",
    "    splitfile = open( inputfile, 'r').read().split('\\n')\n",
    "\n",
    "    #os change directory and write outputfile:\n",
    "    path= \"./\"+splitdir+\"/\"\n",
    "    os.chdir(path)\n",
    "\n",
    "    at = 1\n",
    "    for lines in range(0, len(splitfile), splitLen):\n",
    "        # First, get the list slice\n",
    "        outputData = splitfile[lines:lines+splitLen]\n",
    "        # Now open the output file, join the new slice with newlines\n",
    "        # and write it out. Then close the file.\n",
    "        output = open(outputname +\"_\" +str(at), 'w')\n",
    "        output.write('\\n'.join(outputData))\n",
    "        output.close()\n",
    "        # Increment the counter\n",
    "        at += 1\n",
    "\n",
    "    #time necessary to start blastn\n",
    "    print(\"Starting blastn:it will take a while...so wait!!!!\\n\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    #biopython blast:\n",
    "    l=len(os.listdir(os.curdir))\n",
    "    for count,file in enumerate(os.listdir(os.curdir)):\n",
    "        while (True):\n",
    "            try:\n",
    "                outfmt6=\"6 qseqid saccver pident evalue staxids ssciname sskingdom\"\n",
    "                cline=NcbiblastnCommandline(query=file, max_target_seqs=\"10\", db=\"nt\",\n",
    "                                    outfmt=outfmt6, out=file+\".tsv\", remote=True)\n",
    "                cline()\n",
    "                break\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nKeyboard interruption\")\n",
    "                alt=str(input(\"Continue?:\"))\n",
    "                if alt[0]=='y':\n",
    "                    continue\n",
    "                else:\n",
    "                    quit()\n",
    "            except HTTPError as err:\n",
    "                print(\"\\nHTTPE error connection\")\n",
    "                alt=str(input(\"Continue?:\"))\n",
    "                if alt[0]=='y':\n",
    "                    continue\n",
    "                else:\n",
    "                    quit()\n",
    "                except OSError as err:\n",
    "                    print(\"\\nConnection error\")\n",
    "                    alt=str(input(\"Continue?:\"))\n",
    "                    if alt[0]=='y':\n",
    "                        continue\n",
    "                    else:\n",
    "                        quit()\n",
    "\n",
    "    merge=pd.concat((pd.read_csv(f, sep='\\t', names=['seqid', 'accession', 'identity', 'evalue', 'taxids', 'sciname', 'kingdom']) for f in sorted(glob.iglob('*.tsv'))),\n",
    "                  ignore_index=True, sort=False)\n",
    "    merge.to_csv('blast_'+ outputname+'.tsv',sep='\\t', index=False)\n",
    "\n",
    "def reduce_blast(blastoutput):\n",
    "    df = pd.read_csv(blastoutput,sep='\\t', header=[0])\n",
    "    n=int(len(df))\n",
    "    df['order']= range(1,n+1,1)\n",
    "    df['blast_frequency']=1\n",
    "    df = df.groupby(['seqid', 'sciname','taxids']).agg({'accession':'first', 'identity':'max',\n",
    "                                  'evalue':'min','blast_frequency': 'sum','order':'first'}).reset_index()\n",
    "    df = df.loc[df.groupby(['seqid'])['blast_frequency'].idxmax()].reset_index()\n",
    "    df = df.sort_values('order')\n",
    "    df = df[['seqid','accession','identity','evalue','sciname','taxids']]\n",
    "    return df\n",
    "\n",
    "def add_taxonomy(dataframe):\n",
    "    listtax=[]\n",
    "\n",
    "    for taxid in dataframe['taxids']:\n",
    "    try:\n",
    "        lineage =  ncbi.get_lineage(int(taxid))\n",
    "\n",
    "    except ValueError:\n",
    "        print('Value error')\n",
    "    phylum = clas = order = family = genus = specie = \"NaN\"  # Initializing\n",
    "\n",
    "    if lineage is not None:\n",
    "        for z in range(len(lineage)):\n",
    "            lineage_rank = ncbi.get_rank([lineage[z]])\n",
    "\n",
    "            # Checking the rank and getting their name\n",
    "            if \"phylum\" == lineage_rank[lineage[z]]:\n",
    "                rank_tmp = ncbi.get_taxid_translator([lineage[z]])\n",
    "                phylum = rank_tmp[lineage[z]]\n",
    "\n",
    "            if \"class\" == lineage_rank[lineage[z]]:\n",
    "                rank_tmp = ncbi.get_taxid_translator([lineage[z]])\n",
    "                clas = rank_tmp[lineage[z]]\n",
    "\n",
    "            if \"order\" == lineage_rank[lineage[z]]:\n",
    "                rank_tmp = ncbi.get_taxid_translator([lineage[z]])\n",
    "                order = rank_tmp[lineage[z]]\n",
    "\n",
    "            if \"family\" == lineage_rank[lineage[z]]:\n",
    "                rank_tmp = ncbi.get_taxid_translator([lineage[z]])\n",
    "                family = rank_tmp[lineage[z]]\n",
    "\n",
    "            if \"genus\" == lineage_rank[lineage[z]]:\n",
    "                rank_tmp = ncbi.get_taxid_translator([lineage[z]])\n",
    "                genus = rank_tmp[lineage[z]]\n",
    "\n",
    "            if \"species\" == lineage_rank[lineage[z]]:\n",
    "                rank_tmp = ncbi.get_taxid_translator([lineage[z]])\n",
    "                specie = rank_tmp[lineage[z]]\n",
    "\n",
    "    taxa_list = \";\".join([phylum, clas, order, family, genus, specie])\n",
    "    listtax.append(taxa_list)\n",
    "\n",
    "    dataframe['taxonomy']=listtax\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "HR_uPR9eDPO8",
    "outputId": "b7fc0be0-f3f9-4050-cd8c-eddd015ab715"
   },
   "outputs": [],
   "source": [
    "df=reduce_blast('/home/alberto/working/healthy/blast_top_sequences_healthy.tsv')\n",
    "add_taxonomy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "colab_type": "code",
    "id": "GSOtpctLej_4",
    "outputId": "286b5818-39f2-4870-8375-e4edd7e8a2ec"
   },
   "outputs": [],
   "source": [
    "seq_blast( '/home/alberto/working/','top_sequences_healthy.fasta',400, 'healthy' )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "blast_final_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
